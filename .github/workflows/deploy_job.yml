name: Deploy Databricks Job

on:
  push:
    branches:
      - dev
      - master
    paths:
      - 'mlops/jobs/**'
      - '.github/workflows/deploy_job.yml'

jobs:
  deploy_job:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: mlops/jobs

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Databricks CLI
        run: pip install --upgrade databricks-cli

      - name: Set Databricks environment
        run: |
          echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST }}" >> $GITHUB_ENV
          echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN }}" >> $GITHUB_ENV

      - name: Configure Databricks Jobs API
        run: databricks jobs configure --version=2.1

      - name: Inject cluster ID
        env:
          EXISTING_CLUSTER_ID: ${{ secrets.EXISTING_CLUSTER_ID }}
        run: |
          envsubst < predict_job_config.json > tmp.json
          mv tmp.json predict_job_config.json

      - name: Check JSON content
        run: cat predict_job_config.json

      - name: Create or update Databricks job
        run: |
          set -e

          JOB_NAME=$(jq -r '.name' predict_job_config.json)
          echo "Checking if job '$JOB_NAME' exists..."

          JOB_ID=$(databricks jobs list --output JSON | jq -r ".jobs[] | select(.settings.name==\"$JOB_NAME\") | .job_id")

          if [ -n "$JOB_ID" ] && [ "$JOB_ID" != "null" ]; then
            echo "Job exists (ID: $JOB_ID). Resetting..."
            databricks jobs reset --job-id "$JOB_ID" --json "$(cat predict_job_config.json)"
            echo "Job reset successfully."
          else
            echo "Job does not exist. Creating new one..."
            databricks jobs create --json "$(cat predict_job_config.json)"
            echo "Job created successfully."
          fi
